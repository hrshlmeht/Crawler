A basic web scrawler has been implemented. Used multi tthreading concept and have made 8 threads in the project.

After the input URL is enteted the urls which are associated with the input URL are stored in the txt file (visited)

Concept of daemon thread can be easily understood if one tries to fork this project.

Used python libraries like urllib , thread for the same. 

(It is often misuderstood as beautiful soap library which is another library used for web scrawling in python)

